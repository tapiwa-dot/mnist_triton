# MNIST Digit Classifier with Triton Inference Server

Complete beginner-friendly project for deploying a TensorFlow model with NVIDIA Triton.

## ğŸ“‹ Prerequisites

- Docker installed
- Python 3.8+
- Basic understanding of machine learning

## ğŸš€ Quick Start

### 1. Install Python Dependencies

```bash
pip install tensorflow numpy pillow flask tritonclient[all] tf2onnx
```

### 2. Train and Export Model

```bash
python train_and_export.py
```

This will:
- Download MNIST dataset
- Train a CNN model (5 epochs, ~99% accuracy)
- Export to SavedModel format
- Export to ONNX format (optional)
- Create `model_repository/mnist_savedmodel/1/` directory

### 3. Create Triton Configuration

Create `model_repository/mnist_savedmodel/config.pbtxt`:

```protobuf
name: "mnist_savedmodel"
platform: "tensorflow_savedmodel"
max_batch_size: 8

input [
  {
    name: "input_1"
    data_type: TYPE_FP32
    dims: [ 28, 28, 1 ]
  }
]

output [
  {
    name: "dense_1"
    data_type: TYPE_FP32
    dims: [ 10 ]
  }
]

dynamic_batching {
  max_queue_delay_microseconds: 100
}
```

**Note**: Update `input_1` and `dense_1` names if your model uses different layer names. Check with:

```python
import tensorflow as tf
model = tf.keras.models.load_model('model_repository/mnist_savedmodel/1')
print("Input:", model.input.name)
print("Output:", model.output.name)
```

### 4. Start Triton Server

```bash
docker run --rm -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  -v $(pwd)/model_repository:/models \
  nvcr.io/nvidia/tritonserver:23.10-py3 \
  tritonserver --model-repository=/models
```

Wait for: `Started HTTPService at 0.0.0.0:8000`

### 5. Test with Python Client

```bash
python triton_client.py path/to/digit_image.png
```

### 6. Launch Web Interface

```bash
# Create templates directory
mkdir -p templates

# Start Flask app
python app.py
```

Visit: `http://localhost:5000`

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ train_and_export.py       # Model training script
â”œâ”€â”€ triton_client.py           # Command-line test client
â”œâ”€â”€ app.py                     # Flask web server
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Web interface
â””â”€â”€ model_repository/
    â””â”€â”€ mnist_savedmodel/
        â”œâ”€â”€ config.pbtxt       # Triton configuration
        â””â”€â”€ 1/                 # Model version
            â”œâ”€â”€ saved_model.pb
            â””â”€â”€ variables/
```

## ğŸ¯ Skills Learned

### 1. Model Export
- âœ… TensorFlow SavedModel format
- âœ… ONNX conversion (cross-framework)
- âœ… Model versioning

### 2. Triton Configuration
- âœ… Input/output tensor specifications
- âœ… Dynamic batching
- âœ… Platform selection (TensorFlow/ONNX)
